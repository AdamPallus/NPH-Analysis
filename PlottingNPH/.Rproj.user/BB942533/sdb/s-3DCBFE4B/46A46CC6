{
    "contents" : "---\ntitle: \"NPH-Full\"\nauthor: \"Adam\"\ndate: \"November 24, 2015\"\noutput: html_document\n---\n#Introduction\nThis is an analysis of cells believed to be recorded in the NPH of a normal monkey (Bee) and a monkey with exotropia (Patos). The NPH is thought to provide the horizontal integrator for the control of eye movements. Individual neurons in NPH are typically described as either burst-tonic or tonic cells, with activity related to either the position or position and velocity of the eyes. \n\n#Data Processing\n* Load .csv files from the appropriate directory. These .csv files were creating using matlab.\n* Calclate the lead time for each neuron.\n+ shift data from cell and eye coils to align based on lead time\n* Identify saccades.\n\n\n```{r echo=FALSE} \nlibrary(knitr)\nopts_chunk$set(echo=FALSE)\n```\n\n```{r,message=FALSE}\n\nlibrary(ggplot2)\nlibrary(dplyr)\nlibrary(knitr)\nlibrary(tidyr)\nlibrary(broom)\nlibrary(grid)\nlibrary(relaimpo)\nlibrary(leaps)\n#library(data.table)\nlibrary(stringr)\n```\n\n```{r helperfunctions}\n\nspikedensity<-function (rasters,sd=100) {\n  gsize<- sd*10\n  g<-dnorm(-gsize:gsize,mean=0,sd=sd)\n  sdf<-convolve(rasters,g,type=\"open\")\n  sdf<-sdf[gsize:(length(sdf)-(gsize+1))]*1000\n  sdf\n}\n\ndynamiclead<-function(p,lags=seq(10,300,by=10)) {\n  \n  rsq<-NULL\n  for (i in 1:length(lags)) {\n    if (lags[i] > 0){\n      p$sdflag<-dplyr::lag(p$sdf,lags[i])\n    }\n    else{\n      p$sdflag<-dplyr::lead(p$sdf,lags[i]*-1)\n    }\n    \n    rsq[i]<- summary(lm(sdflag~rep+lep+repV+lepV,data=p))$r.squared\n  }\n  #return(rsq)\n  return(lags[rsq==max(rsq)])\n}\n\nfindSaccades<-function(ev){\n  \n  i<-which(abs(ev)>10) #find all the times when speed > threshold\n  sacoff<-which(diff(i)>15) #minimum duration of an accepted saccade\n  sacon<-c(1,sacoff+1) #first saccade\n  sacoff<-c(sacoff,length(i)) #end of last saccade\n  saccade.onset<-i[sacon] #get actual times\n  saccade.offset<-i[sacoff] \n  return(data.frame(saccade.onset,saccade.offset))\n}\n\nmarkSaccades<-function(ev){\n  #this function finds and marks saccades given a velocity input\n  stimes<-findSaccades(ev)\n  \n  nsaccades=nrow(stimes)\n  \n  #add 10ms buffer to saccade onset and offset\n  #extra code to make sure there is at least that much space in the data\n  buffer<- 15\n  if(stimes$saccade.onset[1]>buffer+1){\n  stimes$saccade.onset=stimes$saccade.onset-10\n  }else{\n    stimes$saccade.onset[2:nsaccades] = stimes$saccade.onset[2:nsaccades]-10\n    stimes$saccade.onset[1]=1\n  }\n  if (stimes$saccade.offset[nsaccades]+buffer<length(ev)){\n    stimes$saccade.offset=stimes$saccade.offset+buffer\n  }else{\n    stimes$saccade.offset[1:nsaccades-1]=stimes$saccade.offset[1:nsaccades-1]+buffer\n    stimes$saccade.offset[nsaccades]=length(ev)\n  }\n    \n  s<-1:length(ev)*0\n  \n  for (k in 1:nsaccades){\n    s[stimes$saccade.onset[k]:stimes$saccade.offset[k]]<-k\n    if(k>1){\n      s[stimes$saccade.offset[k-1]:stimes$saccade.onset[k]]<-(k*-1)\n    }\n  }\n  s[1:stimes$saccade.onset[1]]<- -1\n  s[stimes$saccade.offset[nrow(stimes)]:length(s)]<- (nrow(stimes)*-1)\n  return(s)\n}\n```\n\n```{r loadfiles,cache=TRUE}\n#load all the .csv files in the data folder, then add a column naming the neuron, \n#using the file name as the default name, then put them all together in one long data frame\n\n#path<-\"~/GitHub/NPH-Analysis/practicedata/\"\n#path<-\"~/GitHub/NPH-Analysis/data/\"\npath<-\"~/GitHub/NPH-Analysis/DataRaster/\"\nfiles <- list.files(path=path,pattern='*.csv')\n# files<-files[grepl('Patos',files)] # just look at patos files\n# files<-files[grepl('Bee',files)] # just look at bee files\nt<-data.frame()\nnfiles<-length(files)\n#nfiles=2\nfor (i in 1:nfiles) {\n  f<-files[i]\n  temp <- read.csv(paste(path,f,sep=''))\n  names<-str_match(f,\"(^[a-zA-Z]+)-([0-9]+)\")\n  temp$neuron<-names[1]\n  temp$monkey<-names[2]\n  temp$cellnum<-names[3]\n  temp$sdf<-spikedensity(temp$rasters)\n  leadtime<-dynamiclead(temp)\n  temp<-mutate(temp,sdflag=lag(sdf,leadtime),s=markSaccades((sqrt(rev^2)+sqrt(revV^2))/2),time=row_number())\n  \n  t <-rbind(t,temp)\n\n  }\n```\n\n```{r dosomething}\n\nt %>%\n  group_by(neuron,s) %>%\n  mutate(meanfr=mean(sdflag),\n            R.Hor=mean(rep),\n            R.Ver=mean(repV),\n            L.Hor=mean(lep),\n            L.Ver=mean(lepV),\n            nspikes=mean(rasters),\n            dur=n(),\n            nspk=sum(rasters)/dur*100,\n            R.H.Amp=rep[1]-rep[length(rep)],\n            L.H.Amp=lep[1]-lep[length(lep)],\n            R.V.Amp=repV[1]-repV[length(repV)],\n            L.V.Amp=lepV[1]-lepV[length(lepV)],\n            maxamp=max(abs(R.H.Amp),abs(R.V.Amp),abs(L.H.Amp),abs(L.V.Amp)))->\n  m\n\n#write.csv(m,\"NPHFullData.csv\")\n\nt %>%\n  group_by(neuron,s) %>%\n  summarize(meanfr=mean(sdflag),\n            R.Hor=mean(rep),\n            R.Ver=mean(repV),\n            L.Hor=mean(lep),\n            L.Ver=mean(lepV),\n            nspikes=mean(rasters),\n            dur=n(),\n            nspk=sum(rasters)/dur*100)->\n  summaryforplot\n\n```\n\n```{r colorplot,fig.height=40,fig.width=12}\nqplot(R.Hor,R.Ver,color=meanfr,data=filter(summaryforplot,s<0,dur>200))+facet_wrap(~neuron,ncol=2)+geom_point(size=4)\n```\n\n\n```{r BICcalc}\n#This function can either just calculate the relative importance or use bootstrapping to find a confidence interval for the relative importance. Bootstrapping obviously takes a long time. Also, it can either fit the model to all of the saccades, or just the disjunctive ones. \nminAmp<-5\nm %>%\n  filter(maxamp>minAmp,sdflag>10,s>0) %>%\n  #filter(maxamp>minAmp & disjEither,sdflag>10) %>%\n  group_by(neuron) %>%\n#    do(b=boot.relimp(lm(\"sdflag~rep+rev+repV+revV+lep+lev+lepV+levV\",.),b=1999),\n    do(b=calc.relimp(lm(\"sdflag~rep+rev+repV+revV+lep+lev+lepV+levV\",.)),\n    bic=regsubsets(sdflag~rep+rev+repV+revV+lep+lev+lepV+levV,.)) ->\n  bb\n\nfor (i in 1:nrow(bb)){\n#  b<-booteval.relimp(bb$b[[i]])\n  b<-bb$b[[i]]\n  plot(b, main=bb$neuron[i])\n  plot(bb$bic[[i]],main=bb$neuron[i])\n  plot(bb$bic[[i]],scale=c('adjr2'),main=bb$neuron[i])\n}\n```\n\n```{r dumpdata}\n#only needs to be run once. The plan is to take this analyzed data and use it to make a shiny app load quickly\n#saveRDS(bb,file='NPHFULLBIC.Rda')\nwrite.csv(summaryforplot,'NPHFULLplotsummary.csv')\n\n```\n",
    "created" : 1448394890520.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "35|22|107|3|\n",
    "hash" : "81473672",
    "id" : "46A46CC6",
    "lastKnownWriteTime" : 1448917903,
    "path" : "~/GitHub/NPH-Analysis/PlottingNPH/NPH-Full.Rmd",
    "project_path" : "NPH-Full.Rmd",
    "properties" : {
        "tempName" : "Untitled2"
    },
    "relative_order" : 10,
    "source_on_save" : false,
    "type" : "r_markdown"
}