group_by(neuron) %>%
#    do(b=boot.relimp(lm("sdflag~rep+rev+repV+revV+lep+lev+lepV+levV",.),b=1999),
do(b=calc.relimp(lm("shiftsdf~rep+rev+repV+revV+lep+lev+lepV+levV",.)),
bic=regsubsets(shiftsdf~rep+rev+repV+revV+lep+lev+lepV+levV,.)) ->
bb
tt %>%
filter(maxamp>minAmp,shiftsdf>10) %>%
#filter(maxamp>minAmp & disjEither,sdflag>10) %>%
group_by(neuron) %>%
#    do(b=boot.relimp(lm("sdflag~rep+rev+repV+revV+lep+lev+lepV+levV",.),b=1999),
do(b=calc.relimp(lm("shiftsdf~rep+rev+repV+revV+lep+lev+lepV+levV",.)),
bic=regsubsets(shiftsdf~rep+rev+repV+revV+lep+lev+lepV+levV,.)) ->
bb
head(tt)
filter(tt,neuron=="Bee-11")
install.packages("shiny")
rmarkdown::run(shinytest.Rmd)
rmarkdown::run("shinytest.Rmd")
library(ggplot2)
library(dplyr)
library(knitr)
library(tidyr)
library(broom)
library(grid)
library(relaimpo)
library(leaps)
library(data.table)
#load all the .csv files in the data folder, then add a column naming the neuron,
#using the file name as the default name, then put them all together in one long data frame
#path<-"~/GitHub/NPH-Analysis/practicedata/"
path<-"~/GitHub/NPH-Analysis/data/"
#path<-"~/GitHub/NPH-Analysis/testdata/"
files <- list.files(path=path,pattern='*.csv')
# files<-files[grepl('Patos',files)] # just look at patos files
# files<-files[grepl('Bee',files)] # just look at bee files
t<-data.frame()
for (i in 1:length(files)) {
temp <- read.csv(paste(path,files[i],sep=''))
temp$neuron<-gsub('.csv','',files[i])
t <-rbind(t,temp)
}
findSaccades<-function(ev){
i<-which(abs(ev)>10) #find all the times when speed > threshold
sacoff<-which(diff(i)>15) #minimum duration of an accepted saccade
sacon<-c(1,sacoff+1) #first saccade
sacoff<-c(sacoff,length(i)) #end of last saccade
saccade.onset<-i[sacon] #get actual times
saccade.offset<-i[sacoff]
return(data.frame(saccade.onset,saccade.offset))
}
markSaccades<-function(ev){
#this function finds and marks saccades given a velocity input
stimes<-findSaccades(ev)
nsaccades=nrow(stimes)
#add 10ms buffer to saccade onset and offset
#extra code to make sure there is at least that much space in the data
buffer<- 15
if(stimes$saccade.onset[1]>buffer+1){
stimes$saccade.onset=stimes$saccade.onset-10
}else{
stimes$saccade.onset[2:nsaccades] = stimes$saccade.onset[2:nsaccades]-10
stimes$saccade.onset[1]=1
}
if (stimes$saccade.offset[nsaccades]+buffer<length(ev)){
stimes$saccade.offset=stimes$saccade.offset+buffer
}else{
stimes$saccade.offset[1:nsaccades-1]=stimes$saccade.offset[1:nsaccades-1]+buffer
stimes$saccade.offset[nsaccades]=length(ev)
}
s<-1:length(ev)*0
for (k in 1:nsaccades){
s[stimes$saccade.onset[k]:stimes$saccade.offset[k]]<-k
if(k>1){
s[stimes$saccade.offset[k-1]:stimes$saccade.onset[k]]<-(k*-1)
}
}
s[1:stimes$saccade.onset[1]]<- -1
s[stimes$saccade.offset[nrow(stimes)]:length(s)]<- (nrow(stimes)*-1)
return(s)
}
#use the created functions to mark the saccades
t %>%
mutate(s=markSaccades((sqrt(rev^2)+sqrt(revV^2))/2),time=row_number()) %>%
filter(s>0)-> #mark saccades gives saccades positive numbers and everything else negative
tt
?write.csv
write.csv(tt,"AllData.csv")
tt <-filter(tt,maxamp>minAmp,sdflag>10)
tt %>%
group_by(neuron,s) %>%
summarize(R.H.Amp=rep[1]-rep[length(rep)],
L.H.Amp=lep[1]-lep[length(lep)],
R.V.Amp=repV[1]-repV[length(repV)],
L.V.Amp=lepV[1]-lepV[length(lepV)],
maxamp=max(abs(R.H.Amp),abs(R.V.Amp),abs(L.H.Amp),abs(L.V.Amp))) %>%
mutate(disjH=sign(R.H.Amp*L.H.Amp)<0,disjV=sign(R.V.Amp*L.V.Amp)<0,disjEither=disjH | disjV) ->
amp
tt <-left_join(tt,amp,by=c('s','neuron'))
tt <-filter(tt,maxamp>minAmp,sdflag>10)
tt <-filter(tt,maxamp>5,sdflag>10)
head(tt)
dynamiclead<-function(p,lags=seq(10,300,by=10)) {
rsq<-NULL
for (i in 1:length(lags)) {
if (lags[i] > 0){
p$sdflag<-dplyr::lag(p$sdf,lags[i])
}
else{
p$sdflag<-dplyr::lead(p$sdf,lags[i]*-1)
}
rsq[i]<- summary(lm(sdflag~rep+lep+repV+lepV,data=p))$r.squared
}
#return(rsq)
return(lags[rsq==max(rsq)])
}
t %>%
group_by(neuron) %>%
do(leadtime=dynamiclead(.)) %>%
mutate(leadtime=as.numeric(leadtime)) ->
dl
dl%>%
separate(neuron,c("Monkey","cellnum"),remove =FALSE) %>%
mutate(cellnum=as.numeric(cellnum))->
dlplot
qplot(cellnum,leadtime/5,data=dlplot,binwidth=10)+facet_grid(Monkey~.)+ylab("Lead Time (ms)")
#At this point I have to switch over to using data.table because dplyr can't handle shifting each group by a different amount. Hopefully this doesn't mess everything else up.
dl<-setDT(dl)
t<-setDT(t)
t<-left_join(t,dl,by="neuron")
#the := operator is actually adding the column shiftsdf to the data table
t<-t[,sdflag:=shift(sdf,leadtime[1]),by=neuron]
t<-as.data.frame(t)
findSaccades<-function(ev){
i<-which(abs(ev)>10) #find all the times when speed > threshold
sacoff<-which(diff(i)>15) #minimum duration of an accepted saccade
sacon<-c(1,sacoff+1) #first saccade
sacoff<-c(sacoff,length(i)) #end of last saccade
saccade.onset<-i[sacon] #get actual times
saccade.offset<-i[sacoff]
return(data.frame(saccade.onset,saccade.offset))
}
markSaccades<-function(ev){
#this function finds and marks saccades given a velocity input
stimes<-findSaccades(ev)
nsaccades=nrow(stimes)
#add 10ms buffer to saccade onset and offset
#extra code to make sure there is at least that much space in the data
buffer<- 15
if(stimes$saccade.onset[1]>buffer+1){
stimes$saccade.onset=stimes$saccade.onset-10
}else{
stimes$saccade.onset[2:nsaccades] = stimes$saccade.onset[2:nsaccades]-10
stimes$saccade.onset[1]=1
}
if (stimes$saccade.offset[nsaccades]+buffer<length(ev)){
stimes$saccade.offset=stimes$saccade.offset+buffer
}else{
stimes$saccade.offset[1:nsaccades-1]=stimes$saccade.offset[1:nsaccades-1]+buffer
stimes$saccade.offset[nsaccades]=length(ev)
}
s<-1:length(ev)*0
for (k in 1:nsaccades){
s[stimes$saccade.onset[k]:stimes$saccade.offset[k]]<-k
if(k>1){
s[stimes$saccade.offset[k-1]:stimes$saccade.onset[k]]<-(k*-1)
}
}
s[1:stimes$saccade.onset[1]]<- -1
s[stimes$saccade.offset[nrow(stimes)]:length(s)]<- (nrow(stimes)*-1)
return(s)
}
#use the created functions to mark the saccades
t %>%
mutate(s=markSaccades((sqrt(rev^2)+sqrt(revV^2))/2),time=row_number()) %>%
filter(s>0)-> #mark saccades gives saccades positive numbers and everything else negative
tt
tt %>%
group_by(neuron,s) %>%
summarize(R.H.Amp=rep[1]-rep[length(rep)],
L.H.Amp=lep[1]-lep[length(lep)],
R.V.Amp=repV[1]-repV[length(repV)],
L.V.Amp=lepV[1]-lepV[length(lepV)],
maxamp=max(abs(R.H.Amp),abs(R.V.Amp),abs(L.H.Amp),abs(L.V.Amp))) %>%
mutate(disjH=sign(R.H.Amp*L.H.Amp)<0,disjV=sign(R.V.Amp*L.V.Amp)<0,disjEither=disjH | disjV) ->
amp
tt <-left_join(tt,amp,by=c('s','neuron'))
minAmp<-5
nDisjunctive<-nrow(filter(amp,maxamp>minAmp & disjEither))
nTotal<- nrow(filter(amp,maxamp>minAmp))
tt <-filter(tt,maxamp>minAmp,sdflag>10)
write.csv(tt,"AllDataShiny.csv")
unique(tt$neurons)
unique(tt$neuron)
bb
head(tt)
ttx<-read.csv("AllDataShiny.csv")
head(ttx)
ttx %>%
#filter(maxamp>minAmp & disjEither,sdflag>10) %>%
group_by(neuron) %>%
#    do(b=boot.relimp(lm("sdflag~rep+rev+repV+revV+lep+lev+lepV+levV",.),b=1999),
do(b=calc.relimp(lm("sdflag~rep+rev+repV+revV+lep+lev+lepV+levV",.)),
bic=regsubsets(sdflag~rep+rev+repV+revV+lep+lev+lepV+levV,.)) ->
bb
unique(bb$neuron)
class(unique(bb$neuron))
qplot(sdflag,rep,data=tt)
qplot(sdflag,rep,data=filter(tt,neuron=="Bee-10"))
qplot(rep,sdflag,data=tt)
qplot(rep,sdflag,data=filter(tt,neuron=="Bee-10"))
qplot(rep,sdflag,data=filter(tt,neuron=="Bee-11"))
qplot(rep,sdflag,data=filter(tt,neuron=="Bee-12"))
qplot(rep,sdflag,data=filter(tt,neuron=="Bee-13"))
qplot(rep,sdflag,data=filter(tt,neuron=="Bee-14"))
qplot(rep,sdflag,data=filter(tt,neuron=="Bee-16"))
qplot(rep,sdflag,data=filter(tt,neuron=="Bee-20"))
qplot(rep,sdflag,data=filter(tt,neuron=="Patos-13"))
qplot(rev,sdflag,data=filter(tt,neuron=="Bee-7"))
head(tt)
qplot(time,sdflag,data=filter(tt,neuron="Bee-7"))
qplot(time,sdflag,data=filter(tt,neuron=="Bee-7"))
qplot(time,sdflag,data=filter(tt,neuron=="Bee-7"))+geom_line()
qplot(time,sdflag,data=filter(tt,neuron=="Bee-7"),geom="line")
qplot(time,sdflag,data=filter(tt,neuron=="Bee-10"),geom="line")
qplot(time,sdflag,data=filter(tt,neuron=="Bee-1"),geom="line")
qplot(time,sdflag,data=filter(tt,neuron=="Bee-1",time<100000),geom="line")
library(ggplot2)
library(dplyr)
library(knitr)
library(tidyr)
library(broom)
library(grid)
library(relaimpo)
library(leaps)
#library(data.table)
library(stringr)
spikedensity<-function (rasters,sd=100) {
gsize<- sd*10
g<-dnorm(-gsize:gsize,mean=0,sd=sd)
sdf<-convolve(rasters,g,type="open")
sdf<-sdf[gsize:(length(sdf)-(gsize+1))]*1000
sdf
}
dynamiclead<-function(p,lags=seq(10,300,by=10)) {
rsq<-NULL
for (i in 1:length(lags)) {
if (lags[i] > 0){
p$sdflag<-dplyr::lag(p$sdf,lags[i])
}
else{
p$sdflag<-dplyr::lead(p$sdf,lags[i]*-1)
}
rsq[i]<- summary(lm(sdflag~rep+lep+repV+lepV,data=p))$r.squared
}
#return(rsq)
return(lags[rsq==max(rsq)])
}
findSaccades<-function(ev){
i<-which(abs(ev)>10) #find all the times when speed > threshold
sacoff<-which(diff(i)>15) #minimum duration of an accepted saccade
sacon<-c(1,sacoff+1) #first saccade
sacoff<-c(sacoff,length(i)) #end of last saccade
saccade.onset<-i[sacon] #get actual times
saccade.offset<-i[sacoff]
return(data.frame(saccade.onset,saccade.offset))
}
markSaccades<-function(ev){
#this function finds and marks saccades given a velocity input
stimes<-findSaccades(ev)
nsaccades=nrow(stimes)
#add 10ms buffer to saccade onset and offset
#extra code to make sure there is at least that much space in the data
buffer<- 15
if(stimes$saccade.onset[1]>buffer+1){
stimes$saccade.onset=stimes$saccade.onset-10
}else{
stimes$saccade.onset[2:nsaccades] = stimes$saccade.onset[2:nsaccades]-10
stimes$saccade.onset[1]=1
}
if (stimes$saccade.offset[nsaccades]+buffer<length(ev)){
stimes$saccade.offset=stimes$saccade.offset+buffer
}else{
stimes$saccade.offset[1:nsaccades-1]=stimes$saccade.offset[1:nsaccades-1]+buffer
stimes$saccade.offset[nsaccades]=length(ev)
}
s<-1:length(ev)*0
for (k in 1:nsaccades){
s[stimes$saccade.onset[k]:stimes$saccade.offset[k]]<-k
if(k>1){
s[stimes$saccade.offset[k-1]:stimes$saccade.onset[k]]<-(k*-1)
}
}
s[1:stimes$saccade.onset[1]]<- -1
s[stimes$saccade.offset[nrow(stimes)]:length(s)]<- (nrow(stimes)*-1)
return(s)
}
path<-"~/GitHub/NPH-Analysis/testRaster/"
files <- list.files(path=path,pattern='*.csv')
t<-data.frame()
nfiles<-length(files)
for (i in 1:nfiles) {
f<-files[i]
temp <- read.csv(paste(path,f,sep=''))
names<-str_match(f,"(^[a-zA-Z]+)-([0-9]+)")
temp$neuron<-names[1]
temp$monkey<-names[2]
temp$cellnum<-names[3]
temp$sdf<-spikedensity(temp$rasters)
leadtime<-dynamiclead(temp)
temp<-mutate(temp,sdflag=lag(sdf,leadtime),s=markSaccades((sqrt(rev^2)+sqrt(revV^2))/2),time=row_number())
t <-rbind(t,temp)
}
head(temp)
leadtime<-dynamiclead(temp)
temp<-mutate(temp,sdflag=lag(sdf,leadtime),s=markSaccades((sqrt(rev^2)+sqrt(revV^2))/2),time=row_number())
head(temp)
t <-rbind(t,temp)
n<-2
f<-files[i]
temp <- read.csv(paste(path,f,sep=''))
names<-str_match(f,"(^[a-zA-Z]+)-([0-9]+)")
temp$neuron<-names[1]
temp$monkey<-names[2]
temp$cellnum<-names[3]
temp$sdf<-spikedensity(temp$rasters)
leadtime<-dynamiclead(temp)
temp<-mutate(temp,sdflag=lag(sdf,leadtime),s=markSaccades((sqrt(rev^2)+sqrt(revV^2))/2),time=row_number())
t <-rbind(t,temp)
n<-3
f<-files[i]
temp <- read.csv(paste(path,f,sep=''))
names<-str_match(f,"(^[a-zA-Z]+)-([0-9]+)")
temp$neuron<-names[1]
temp$monkey<-names[2]
temp$cellnum<-names[3]
temp$sdf<-spikedensity(temp$rasters)
leadtime<-dynamiclead(temp)
temp<-mutate(temp,sdflag=lag(sdf,leadtime),s=markSaccades((sqrt(rev^2)+sqrt(revV^2))/2),time=row_number())
t <-rbind(t,temp)
t %>%
group_by(neuron,s) %>%
mutate(meanfr=mean(sdflag),
R.Hor=mean(rep),
R.Ver=mean(repV),
L.Hor=mean(lep),
L.Ver=mean(lepV),
nspikes=mean(rasters),
dur=n(),
nspk=sum(rasters)/dur*100,
R.H.Amp=rep[1]-rep[length(rep)],
L.H.Amp=lep[1]-lep[length(lep)],
R.V.Amp=repV[1]-repV[length(repV)],
L.V.Amp=lepV[1]-lepV[length(lepV)],
maxamp=max(abs(R.H.Amp),abs(R.V.Amp),abs(L.H.Amp),abs(L.V.Amp)))->
m
#write.csv(m,"NPHFullData.csv")
t %>%
group_by(neuron,s) %>%
summarize(meanfr=mean(sdflag),
R.Hor=mean(rep),
R.Ver=mean(repV),
L.Hor=mean(lep),
L.Ver=mean(lepV),
nspikes=mean(rasters),
dur=n(),
nspk=sum(rasters)/dur*100)->
summaryforplot
qplot(R.Hor,R.Ver,color=meanfr,data=filter(summaryforplot,s<0,dur>200))+facet_wrap(~neuron,ncol=2)+geom_point(size=4)
library(ggplot2)
library(dplyr)
library(knitr)
library(tidyr)
library(broom)
library(grid)
library(relaimpo)
library(leaps)
#library(data.table)
library(stringr)
spikedensity<-function (rasters,sd=100) {
gsize<- sd*10
g<-dnorm(-gsize:gsize,mean=0,sd=sd)
sdf<-convolve(rasters,g,type="open")
sdf<-sdf[gsize:(length(sdf)-(gsize+1))]*1000
sdf
}
dynamiclead<-function(p,lags=seq(10,300,by=10)) {
rsq<-NULL
for (i in 1:length(lags)) {
if (lags[i] > 0){
p$sdflag<-dplyr::lag(p$sdf,lags[i])
}
else{
p$sdflag<-dplyr::lead(p$sdf,lags[i]*-1)
}
rsq[i]<- summary(lm(sdflag~rep+lep+repV+lepV,data=p))$r.squared
}
#return(rsq)
return(lags[rsq==max(rsq)])
}
findSaccades<-function(ev){
i<-which(abs(ev)>10) #find all the times when speed > threshold
sacoff<-which(diff(i)>15) #minimum duration of an accepted saccade
sacon<-c(1,sacoff+1) #first saccade
sacoff<-c(sacoff,length(i)) #end of last saccade
saccade.onset<-i[sacon] #get actual times
saccade.offset<-i[sacoff]
return(data.frame(saccade.onset,saccade.offset))
}
markSaccades<-function(ev){
#this function finds and marks saccades given a velocity input
stimes<-findSaccades(ev)
nsaccades=nrow(stimes)
#add 10ms buffer to saccade onset and offset
#extra code to make sure there is at least that much space in the data
buffer<- 15
if(stimes$saccade.onset[1]>buffer+1){
stimes$saccade.onset=stimes$saccade.onset-10
}else{
stimes$saccade.onset[2:nsaccades] = stimes$saccade.onset[2:nsaccades]-10
stimes$saccade.onset[1]=1
}
if (stimes$saccade.offset[nsaccades]+buffer<length(ev)){
stimes$saccade.offset=stimes$saccade.offset+buffer
}else{
stimes$saccade.offset[1:nsaccades-1]=stimes$saccade.offset[1:nsaccades-1]+buffer
stimes$saccade.offset[nsaccades]=length(ev)
}
s<-1:length(ev)*0
for (k in 1:nsaccades){
s[stimes$saccade.onset[k]:stimes$saccade.offset[k]]<-k
if(k>1){
s[stimes$saccade.offset[k-1]:stimes$saccade.onset[k]]<-(k*-1)
}
}
s[1:stimes$saccade.onset[1]]<- -1
s[stimes$saccade.offset[nrow(stimes)]:length(s)]<- (nrow(stimes)*-1)
return(s)
}
path<-"~/GitHub/NPH-Analysis/testRaster/"
files <- list.files(path=path,pattern='*.csv')
t<-data.frame()
nfiles<-length(files)
i<-1
f<-files[i]
temp <- read.csv(paste(path,f,sep=''))
names<-str_match(f,"(^[a-zA-Z]+)-([0-9]+)")
temp$neuron<-names[1]
temp$monkey<-names[2]
temp$cellnum<-names[3]
temp$sdf<-spikedensity(temp$rasters)
leadtime<-dynamiclead(temp)
temp<-mutate(temp,sdflag=lag(sdf,leadtime),s=markSaccades((sqrt(rev^2)+sqrt(revV^2))/2),time=row_number())
t <-rbind(t,temp)
i<-2
f<-files[i]
temp <- read.csv(paste(path,f,sep=''))
names<-str_match(f,"(^[a-zA-Z]+)-([0-9]+)")
temp$neuron<-names[1]
temp$monkey<-names[2]
temp$cellnum<-names[3]
temp$sdf<-spikedensity(temp$rasters)
leadtime<-dynamiclead(temp)
temp<-mutate(temp,sdflag=lag(sdf,leadtime),s=markSaccades((sqrt(rev^2)+sqrt(revV^2))/2),time=row_number())
t <-rbind(t,temp)
i<-3
f<-files[i]
temp <- read.csv(paste(path,f,sep=''))
names<-str_match(f,"(^[a-zA-Z]+)-([0-9]+)")
temp$neuron<-names[1]
temp$monkey<-names[2]
temp$cellnum<-names[3]
temp$sdf<-spikedensity(temp$rasters)
leadtime<-dynamiclead(temp)
head(t)
unique(t$neuron)
i
head(temp)
head(leadtime)
leadtime<-dynamiclead(temp)
temp<-mutate(temp,sdflag=lag(sdf,leadtime),s=markSaccades((sqrt(rev^2)+sqrt(revV^2))/2),time=row_number())
t <-rbind(t,temp)
head(t)
unique(t$neuron)
t %>%
group_by(neuron,s) %>%
mutate(meanfr=mean(sdflag),
R.Hor=mean(rep),
R.Ver=mean(repV),
L.Hor=mean(lep),
L.Ver=mean(lepV),
nspikes=mean(rasters),
dur=n(),
nspk=sum(rasters)/dur*100,
R.H.Amp=rep[1]-rep[length(rep)],
L.H.Amp=lep[1]-lep[length(lep)],
R.V.Amp=repV[1]-repV[length(repV)],
L.V.Amp=lepV[1]-lepV[length(lepV)],
maxamp=max(abs(R.H.Amp),abs(R.V.Amp),abs(L.H.Amp),abs(L.V.Amp)))->
m
#write.csv(m,"NPHFullData.csv")
t %>%
group_by(neuron,s) %>%
summarize(meanfr=mean(sdflag),
R.Hor=mean(rep),
R.Ver=mean(repV),
L.Hor=mean(lep),
L.Ver=mean(lepV),
nspikes=mean(rasters),
dur=n(),
nspk=sum(rasters)/dur*100)->
summaryforplot
qplot(R.Hor,R.Ver,color=meanfr,data=filter(summaryforplot,s<0,dur>200))+facet_wrap(~neuron,ncol=2)+geom_point(size=4)
