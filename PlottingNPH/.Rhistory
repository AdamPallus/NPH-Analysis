gsize<- sd*10
g<-dnorm(-gsize:gsize,mean=0,sd=sd)
sdf<-convolve(rasters,g,type="open")
sdf<-sdf[gsize:(length(sdf)-(gsize+1))]*1000
sdf
}
dynamiclead<-function(p,lags=seq(10,300,by=10)) {
rsq<-NULL
for (i in 1:length(lags)) {
if (lags[i] > 0){
p$sdflag<-dplyr::lag(p$sdf,lags[i])
}
else{
p$sdflag<-dplyr::lead(p$sdf,lags[i]*-1)
}
rsq[i]<- summary(lm(sdflag~rep+lep+repV+lepV,data=p))$r.squared
}
#return(rsq)
return(lags[rsq==max(rsq)])
}
findSaccades<-function(ev){
i<-which(abs(ev)>10) #find all the times when speed > threshold
sacoff<-which(diff(i)>15) #minimum duration of an accepted saccade
sacon<-c(1,sacoff+1) #first saccade
sacoff<-c(sacoff,length(i)) #end of last saccade
saccade.onset<-i[sacon] #get actual times
saccade.offset<-i[sacoff]
return(data.frame(saccade.onset,saccade.offset))
}
markSaccades<-function(ev){
#this function finds and marks saccades given a velocity input
stimes<-findSaccades(ev)
nsaccades=nrow(stimes)
#add 10ms buffer to saccade onset and offset
#extra code to make sure there is at least that much space in the data
buffer<- 15
if(stimes$saccade.onset[1]>buffer+1){
stimes$saccade.onset=stimes$saccade.onset-10
}else{
stimes$saccade.onset[2:nsaccades] = stimes$saccade.onset[2:nsaccades]-10
stimes$saccade.onset[1]=1
}
if (stimes$saccade.offset[nsaccades]+buffer<length(ev)){
stimes$saccade.offset=stimes$saccade.offset+buffer
}else{
stimes$saccade.offset[1:nsaccades-1]=stimes$saccade.offset[1:nsaccades-1]+buffer
stimes$saccade.offset[nsaccades]=length(ev)
}
s<-1:length(ev)*0
for (k in 1:nsaccades){
s[stimes$saccade.onset[k]:stimes$saccade.offset[k]]<-k
if(k>1){
s[stimes$saccade.offset[k-1]:stimes$saccade.onset[k]]<-(k*-1)
}
}
s[1:stimes$saccade.onset[1]]<- -1
s[stimes$saccade.offset[nrow(stimes)]:length(s)]<- (nrow(stimes)*-1)
return(s)
}
path<-"~/GitHub/NPH-Analysis/testRaster/"
files <- list.files(path=path,pattern='*.csv')
t<-data.frame()
nfiles<-length(files)
i<-1
f<-files[i]
temp <- read.csv(paste(path,f,sep=''))
names<-str_match(f,"(^[a-zA-Z]+)-([0-9]+)")
temp$neuron<-names[1]
temp$monkey<-names[2]
temp$cellnum<-names[3]
temp$sdf<-spikedensity(temp$rasters)
leadtime<-dynamiclead(temp)
temp<-mutate(temp,sdflag=lag(sdf,leadtime),s=markSaccades((sqrt(rev^2)+sqrt(revV^2))/2),time=row_number())
t <-rbind(t,temp)
i<-2
f<-files[i]
temp <- read.csv(paste(path,f,sep=''))
names<-str_match(f,"(^[a-zA-Z]+)-([0-9]+)")
temp$neuron<-names[1]
temp$monkey<-names[2]
temp$cellnum<-names[3]
temp$sdf<-spikedensity(temp$rasters)
leadtime<-dynamiclead(temp)
temp<-mutate(temp,sdflag=lag(sdf,leadtime),s=markSaccades((sqrt(rev^2)+sqrt(revV^2))/2),time=row_number())
t <-rbind(t,temp)
i<-3
f<-files[i]
temp <- read.csv(paste(path,f,sep=''))
names<-str_match(f,"(^[a-zA-Z]+)-([0-9]+)")
temp$neuron<-names[1]
temp$monkey<-names[2]
temp$cellnum<-names[3]
temp$sdf<-spikedensity(temp$rasters)
leadtime<-dynamiclead(temp)
head(t)
unique(t$neuron)
i
head(temp)
head(leadtime)
leadtime<-dynamiclead(temp)
temp<-mutate(temp,sdflag=lag(sdf,leadtime),s=markSaccades((sqrt(rev^2)+sqrt(revV^2))/2),time=row_number())
t <-rbind(t,temp)
head(t)
unique(t$neuron)
t %>%
group_by(neuron,s) %>%
mutate(meanfr=mean(sdflag),
R.Hor=mean(rep),
R.Ver=mean(repV),
L.Hor=mean(lep),
L.Ver=mean(lepV),
nspikes=mean(rasters),
dur=n(),
nspk=sum(rasters)/dur*100,
R.H.Amp=rep[1]-rep[length(rep)],
L.H.Amp=lep[1]-lep[length(lep)],
R.V.Amp=repV[1]-repV[length(repV)],
L.V.Amp=lepV[1]-lepV[length(lepV)],
maxamp=max(abs(R.H.Amp),abs(R.V.Amp),abs(L.H.Amp),abs(L.V.Amp)))->
m
#write.csv(m,"NPHFullData.csv")
t %>%
group_by(neuron,s) %>%
summarize(meanfr=mean(sdflag),
R.Hor=mean(rep),
R.Ver=mean(repV),
L.Hor=mean(lep),
L.Ver=mean(lepV),
nspikes=mean(rasters),
dur=n(),
nspk=sum(rasters)/dur*100)->
summaryforplot
qplot(R.Hor,R.Ver,color=meanfr,data=filter(summaryforplot,s<0,dur>200))+facet_wrap(~neuron,ncol=2)+geom_point(size=4)
library(ggplot2)
library(dplyr)
library(knitr)
library(tidyr)
library(broom)
library(grid)
library(relaimpo)
library(leaps)
#library(data.table)
library(stringr)
library(ggplot2)
library(dplyr)
library(knitr)
library(tidyr)
library(broom)
library(grid)
library(relaimpo)
library(leaps)
#library(data.table)
library(stringr)
#load all the .csv files in the data folder, then add a column naming the neuron,
#using the file name as the default name, then put them all together in one long data frame
path<-"~/GitHub/NPH-Analysis/practicedata/"
#path<-"~/GitHub/NPH-Analysis/data/"
# path<-"~/GitHub/NPH-Analysis/DataRaster/"
#path<-"~/GitHub/NPH-Analysis/testRaster/"
files <- list.files(path=path,pattern='*.csv')
# files<-files[grepl('Patos',files)] # just look at patos files
# files<-files[grepl('Bee',files)] # just look at bee files
t<-data.frame()
nfiles<-length(files)
#nfiles=2
for (i in 1:nfiles) {
f<-files[i]
temp <- read.csv(paste(path,f,sep=''))
names<-str_match(f,"(^[a-zA-Z]+)-([0-9]+)")
temp$neuron<-names[1]
temp$monkey<-names[2]
temp$cellnum<-names[3]
temp$sdf<-spikedensity(temp$rasters)
leadtime<-dynamiclead(temp)
temp<-mutate(temp,sdflag=lag(sdf,leadtime),s=markSaccades((sqrt(rev^2)+sqrt(revV^2))/2),time=row_number())
t <-rbind(t,temp)
}
spikedensity<-function (rasters,sd=100) {
gsize<- sd*10
g<-dnorm(-gsize:gsize,mean=0,sd=sd)
sdf<-convolve(rasters,g,type="open")
sdf<-sdf[gsize:(length(sdf)-(gsize+1))]*1000
sdf
}
dynamiclead<-function(p,lags=seq(10,300,by=10)) {
rsq<-NULL
for (i in 1:length(lags)) {
if (lags[i] > 0){
p$sdflag<-dplyr::lag(p$sdf,lags[i])
}
else{
p$sdflag<-dplyr::lead(p$sdf,lags[i]*-1)
}
rsq[i]<- summary(lm(sdflag~rep+lep+repV+lepV,data=p))$r.squared
}
#return(rsq)
return(lags[rsq==max(rsq)])
}
findSaccades<-function(ev){
i<-which(abs(ev)>10) #find all the times when speed > threshold
sacoff<-which(diff(i)>15) #minimum duration of an accepted saccade
sacon<-c(1,sacoff+1) #first saccade
sacoff<-c(sacoff,length(i)) #end of last saccade
saccade.onset<-i[sacon] #get actual times
saccade.offset<-i[sacoff]
return(data.frame(saccade.onset,saccade.offset))
}
markSaccades<-function(ev){
#this function finds and marks saccades given a velocity input
stimes<-findSaccades(ev)
nsaccades=nrow(stimes)
#add 10ms buffer to saccade onset and offset
#extra code to make sure there is at least that much space in the data
buffer<- 15
if(stimes$saccade.onset[1]>buffer+1){
stimes$saccade.onset=stimes$saccade.onset-10
}else{
stimes$saccade.onset[2:nsaccades] = stimes$saccade.onset[2:nsaccades]-10
stimes$saccade.onset[1]=1
}
if (stimes$saccade.offset[nsaccades]+buffer<length(ev)){
stimes$saccade.offset=stimes$saccade.offset+buffer
}else{
stimes$saccade.offset[1:nsaccades-1]=stimes$saccade.offset[1:nsaccades-1]+buffer
stimes$saccade.offset[nsaccades]=length(ev)
}
s<-1:length(ev)*0
for (k in 1:nsaccades){
s[stimes$saccade.onset[k]:stimes$saccade.offset[k]]<-k
if(k>1){
s[stimes$saccade.offset[k-1]:stimes$saccade.onset[k]]<-(k*-1)
}
}
s[1:stimes$saccade.onset[1]]<- -1
s[stimes$saccade.offset[nrow(stimes)]:length(s)]<- (nrow(stimes)*-1)
return(s)
}
#load all the .csv files in the data folder, then add a column naming the neuron,
#using the file name as the default name, then put them all together in one long data frame
path<-"~/GitHub/NPH-Analysis/practicedata/"
#path<-"~/GitHub/NPH-Analysis/data/"
# path<-"~/GitHub/NPH-Analysis/DataRaster/"
#path<-"~/GitHub/NPH-Analysis/testRaster/"
files <- list.files(path=path,pattern='*.csv')
# files<-files[grepl('Patos',files)] # just look at patos files
# files<-files[grepl('Bee',files)] # just look at bee files
t<-data.frame()
nfiles<-length(files)
#nfiles=2
for (i in 1:nfiles) {
f<-files[i]
temp <- read.csv(paste(path,f,sep=''))
names<-str_match(f,"(^[a-zA-Z]+)-([0-9]+)")
temp$neuron<-names[1]
temp$monkey<-names[2]
temp$cellnum<-names[3]
temp$sdf<-spikedensity(temp$rasters)
leadtime<-dynamiclead(temp)
temp<-mutate(temp,sdflag=lag(sdf,leadtime),s=markSaccades((sqrt(rev^2)+sqrt(revV^2))/2),time=row_number())
t <-rbind(t,temp)
}
head(temp)
library(ggplot2)
library(dplyr)
library(knitr)
library(tidyr)
library(broom)
library(grid)
library(relaimpo)
library(leaps)
#library(data.table)
library(stringr)
spikedensity<-function (rasters,sd=100) {
gsize<- sd*10
g<-dnorm(-gsize:gsize,mean=0,sd=sd)
sdf<-convolve(rasters,g,type="open")
sdf<-sdf[gsize:(length(sdf)-(gsize+1))]*1000
sdf
}
dynamiclead<-function(p,lags=seq(10,300,by=10)) {
rsq<-NULL
for (i in 1:length(lags)) {
if (lags[i] > 0){
p$sdflag<-dplyr::lag(p$sdf,lags[i])
}
else{
p$sdflag<-dplyr::lead(p$sdf,lags[i]*-1)
}
rsq[i]<- summary(lm(sdflag~rep+lep+repV+lepV,data=p))$r.squared
}
#return(rsq)
return(lags[rsq==max(rsq)])
}
findSaccades<-function(ev){
i<-which(abs(ev)>10) #find all the times when speed > threshold
sacoff<-which(diff(i)>15) #minimum duration of an accepted saccade
sacon<-c(1,sacoff+1) #first saccade
sacoff<-c(sacoff,length(i)) #end of last saccade
saccade.onset<-i[sacon] #get actual times
saccade.offset<-i[sacoff]
return(data.frame(saccade.onset,saccade.offset))
}
markSaccades<-function(ev){
#this function finds and marks saccades given a velocity input
stimes<-findSaccades(ev)
nsaccades=nrow(stimes)
#add 10ms buffer to saccade onset and offset
#extra code to make sure there is at least that much space in the data
buffer<- 15
if(stimes$saccade.onset[1]>buffer+1){
stimes$saccade.onset=stimes$saccade.onset-10
}else{
stimes$saccade.onset[2:nsaccades] = stimes$saccade.onset[2:nsaccades]-10
stimes$saccade.onset[1]=1
}
if (stimes$saccade.offset[nsaccades]+buffer<length(ev)){
stimes$saccade.offset=stimes$saccade.offset+buffer
}else{
stimes$saccade.offset[1:nsaccades-1]=stimes$saccade.offset[1:nsaccades-1]+buffer
stimes$saccade.offset[nsaccades]=length(ev)
}
s<-1:length(ev)*0
for (k in 1:nsaccades){
s[stimes$saccade.onset[k]:stimes$saccade.offset[k]]<-k
if(k>1){
s[stimes$saccade.offset[k-1]:stimes$saccade.onset[k]]<-(k*-1)
}
}
s[1:stimes$saccade.onset[1]]<- -1
s[stimes$saccade.offset[nrow(stimes)]:length(s)]<- (nrow(stimes)*-1)
return(s)
}
#load all the .csv files in the data folder, then add a column naming the neuron,
#using the file name as the default name, then put them all together in one long data frame
path<-"~/GitHub/NPH-Analysis/testdata/"
#path<-"~/GitHub/NPH-Analysis/data/"
# path<-"~/GitHub/NPH-Analysis/DataRaster/"
#path<-"~/GitHub/NPH-Analysis/testRaster/"
files <- list.files(path=path,pattern='*.csv')
# files<-files[grepl('Patos',files)] # just look at patos files
# files<-files[grepl('Bee',files)] # just look at bee files
t<-data.frame()
nfiles<-length(files)
#nfiles=2
for (i in 1:nfiles) {
f<-files[i]
temp <- read.csv(paste(path,f,sep=''))
names<-str_match(f,"(^[a-zA-Z]+)-([0-9]+)")
temp$neuron<-names[1]
temp$monkey<-names[2]
temp$cellnum<-names[3]
temp$sdf<-spikedensity(temp$rasters)
leadtime<-dynamiclead(temp)
temp<-mutate(temp,sdflag=lag(sdf,leadtime),s=markSaccades((sqrt(rev^2)+sqrt(revV^2))/2),time=row_number())
t <-rbind(t,temp)
}
head(t)
t %>%
group_by(neuron,s) %>%
mutate(meanfr=mean(sdflag),
R.Hor=mean(rep),
R.Ver=mean(repV),
L.Hor=mean(lep),
L.Ver=mean(lepV),
nspikes=mean(rasters),
dur=n(),
nspk=sum(rasters)/dur*100,
R.H.Amp=rep[1]-rep[length(rep)],
L.H.Amp=lep[1]-lep[length(lep)],
R.V.Amp=repV[1]-repV[length(repV)],
L.V.Amp=lepV[1]-lepV[length(lepV)],
maxamp=max(abs(R.H.Amp),abs(R.V.Amp),abs(L.H.Amp),abs(L.V.Amp)))->
m
#write.csv(m,"NPHFullData.csv")
t %>%
group_by(neuron,s) %>%
summarize(meanfr=mean(sdflag),
R.Hor=mean(rep),
R.Ver=mean(repV),
L.Hor=mean(lep),
L.Ver=mean(lepV),
nspikes=mean(rasters),
dur=n(),
nspk=sum(rasters)/dur*100)->
summaryforplot
qplot(R.Hor,R.Ver,color=meanfr,data=filter(summaryforplot,s<0,dur>200))+facet_wrap(~neuron,ncol=2)+geom_point(size=4)+
ggtitle("Static Fixations")
t %>%
group_by(neuron,s) %>%
summarize(meanfr=mean(sdflag),
maxfr=max(sdflag),
R.Hor=mean(rep),
R.Ver=mean(repV),
L.Hor=mean(lep),
L.Ver=mean(lepV),
nspikes=mean(rasters),
dur=n(),
nspk=sum(rasters)/dur*100)->
summaryforplot
qplot(R.Hor,R.Ver,color=meanfr/maxfr,data=filter(summaryforplot,s<0,dur>200))+facet_wrap(~neuron,ncol=2)+geom_point(size=4)+
ggtitle("Static Fixations")
head(summaryforplot)
qplot(R.Hor,R.Ver,color=maxfr,data=filter(summaryforplot,s<0,dur>200))+facet_wrap(~neuron,ncol=2)+geom_point(size=4)+
ggtitle("Static Fixations")
summaryforplot %>% group_by(neuron) %>% mutate(maxfr=max(meanfr)) -> sfp
qplot(R.Hor,R.Ver,color=meanfr/maxfr,data=filter(sfp,s<0,dur>200))+facet_wrap(~neuron,ncol=2)+geom_point(size=4)+
ggtitle("Static Fixations")
qplot(R.Hor,R.Ver,color=meanfr,data=filter(sfp,s<0,dur>200))+facet_wrap(~neuron,ncol=2)+geom_point(size=4)+
ggtitle("Static Fixations")
qplot(R.Hor,R.Ver,color=maxfr,data=filter(sfp,s<0,dur>200))+facet_wrap(~neuron,ncol=2)+geom_point(size=4)+
ggtitle("Static Fixations")
qplot(R.Hor,R.Ver,color=(meanfr/maxfr),data=filter(sfp,s<0,dur>200))+facet_wrap(~neuron,ncol=2)+geom_point(size=4)+
ggtitle("Static Fixations")
head(sfp)
tail(sfp)
summaryforplot %>% mutate(maxfr=max(meanfr)) -> sfp
head(sfp)
max(sfp$maxfr)
summaryforplot %>% group_by(neuron) %>% mutate(maxfr=max(meanfr,na.rm=T)) -> sfp
head(sfp)
qplot(R.Hor,R.Ver,color=(meanfr/maxfr),data=filter(sfp,s<0,dur>200))+facet_wrap(~neuron,ncol=2)+geom_point(size=4)+
ggtitle("Static Fixations")
qplot(R.Hor,R.Ver,color=meanfr/maxfr,data=filter(sfp,s<0,dur>200))+facet_wrap(~neuron,ncol=2)+geom_point(size=4)+
ggtitle("Static Fixations")
b22<-filter(sfp,neuron=='Bee-22')
qplot(b22$meanfr)
qplot(meanfr,data=filter(b22,meanfr>10))
qplot(R.Hor,meanfr,data=filter(b22,meanfr>10))
qplot(R.Hor,meanfr,data=filter(b22,meanfr>0))
qplot(R.Hor,meanfr,data=filter(b22,meanfr>0))+stat_smooth(method=lm)
qplot(R.Hor,meanfr,data=filter(b22,meanfr>10))+stat_smooth(method=lm)
b23<-filter(sfp,neuron=='Bee-23')
qplot(R.Hor,meanfr,data=filter(b23,meanfr>10))+stat_smooth(method=lm)
qplot(R.Hor,meanfr,data=filter(b22,meanfr>10,dur>75))+stat_smooth(method=lm)
qplot(R.Hor,meanfr,data=filter(b22,meanfr>10,dur>200))+stat_smooth(method=lm)
qplot(R.Hor,R.Ver,color=meanfr,data=filter(summaryforplot,s<0,dur>200,meanfr>10))+facet_wrap(~neuron,ncol=2)+geom_point(size=4)+
ggtitle("Static Fixations")
qplot(R.Hor,R.Ver,color=meanfr,data=filter(summaryforplot,s<0,dur>200,nspikes>5))+facet_wrap(~neuron,ncol=2)+geom_point(size=4)+
ggtitle("Static Fixations")
qplot(R.Hor,R.Ver,color=meanfr,data=filter(summaryforplot,s<0,dur>200,nspikes>5))+facet_wrap(~neuron,ncol=2)+geom_point(size=4)+
ggtitle("Static Fixations")
qplot(R.Hor,R.Ver,color=meanfr,data=filter(summaryforplot,s<0,dur>200,nspk>5))+facet_wrap(~neuron,ncol=2)+geom_point(size=4)+
ggtitle("Static Fixations")
qplot(R.Hor,R.Ver,color=meanfr,data=filter(summaryforplot,s<0,dur>200,nspk>2))+facet_wrap(~neuron,ncol=2)+geom_point(size=4)+
ggtitle("Static Fixations")
t %>%
group_by(neuron,s) %>%
summarize(meanfr=mean(sdflag),
R.Hor=mean(rep),
R.Ver=mean(repV),
L.Hor=mean(lep),
L.Ver=mean(lepV),
nspikes=sum(rasters),
dur=n(),
nspk=sum(rasters)/dur*100)->
summaryforplot
qplot(R.Hor,R.Ver,color=meanfr,data=filter(summaryforplot,s<0,dur>200,nspikes>2))+facet_wrap(~neuron,ncol=2)+geom_point(size=4)+
ggtitle("Static Fixations")
head(m)
t %>%
group_by(neuron,s) %>%
mutate(meanfr=mean(sdflag),
R.Hor=mean(rep),
R.Ver=mean(repV),
L.Hor=mean(lep),
L.Ver=mean(lepV),
nspikes=sum(rasters),
dur=n(),
nspk=sum(rasters)/dur*100,
R.H.Amp=rep[1]-rep[length(rep)],
L.H.Amp=lep[1]-lep[length(lep)],
R.V.Amp=repV[1]-repV[length(repV)],
L.V.Amp=lepV[1]-lepV[length(lepV)],
maxamp=max(abs(R.H.Amp),abs(R.V.Amp),abs(L.H.Amp),abs(L.V.Amp)))->
m
minAmp<-5
m %>%
filter(maxamp>minAmp,nspikes>2,s<0) %>%
#filter(maxamp>minAmp,sdflag>10,s>0) %>%
#filter(maxamp>minAmp & disjEither,sdflag>10) %>%
group_by(neuron) %>%
#    do(b=boot.relimp(lm("sdflag~rep+rev+repV+revV+lep+lev+lepV+levV",.),b=1999),
do(b=calc.relimp(lm("sdflag~rep+rev+repV+revV+lep+lev+lepV+levV",.)),
bic=regsubsets(sdflag~rep+rev+repV+revV+lep+lev+lepV+levV,.)) ->
bb
for (i in 1:nrow(bb)){
#  b<-booteval.relimp(bb$b[[i]])
b<-bb$b[[i]]
plot(b, main=bb$neuron[i])
plot(bb$bic[[i]],main=bb$neuron[i])
plot(bb$bic[[i]],scale=c('adjr2'),main=bb$neuron[i])
}
head(bb)
head(m)
max(m$nspikes)
min(m$nspikes)
m %>%
filter(nspikes>2,s<0) %>%
#filter(maxamp>minAmp,sdflag>10,s>0) %>%
#filter(maxamp>minAmp & disjEither,sdflag>10) %>%
group_by(neuron) %>%
#    do(b=boot.relimp(lm("sdflag~rep+rev+repV+revV+lep+lev+lepV+levV",.),b=1999),
do(b=calc.relimp(lm("sdflag~rep+rev+repV+revV+lep+lev+lepV+levV",.)),
bic=regsubsets(sdflag~rep+rev+repV+revV+lep+lev+lepV+levV,.)) ->
bb
for (i in 1:nrow(bb)){
#  b<-booteval.relimp(bb$b[[i]])
b<-bb$b[[i]]
plot(b, main=bb$neuron[i])
plot(bb$bic[[i]],main=bb$neuron[i])
plot(bb$bic[[i]],scale=c('adjr2'),main=bb$neuron[i])
}
