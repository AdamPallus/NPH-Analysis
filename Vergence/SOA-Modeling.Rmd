---
title: "SOA Modeling"
author: "Adam"
date: "September 14, 2016"
output: 
  html_document: 
    keep_md: yes
---

```{r setup, include=FALSE,message=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(ggplot2)
library(knitr)
library(tidyr)
library(broom)
# library(grid)
library(relaimpo)
library(leaps)
#library(data.table)
library(stringr)
library(dplyr)
# source('joinsaccadesuniform.R')
# source('Adamhelperfunctions.R')
```

```{r echo=FALSE} 
library(knitr)
opts_chunk$set(echo=FALSE,message=FALSE,warning=FALSE,cache=FALSE)
```

```{r HelperFunctions}


spikedensity<-function (rasters,sd=100) {
  gsize<- sd*10
  g<-dnorm(-gsize:gsize,mean=0,sd=sd)
  sdf<-convolve(rasters,g,type="open")
  sdf<-sdf[gsize:(length(sdf)-(gsize+1))]*1000
  sdf
}

dynamiclead<-function(p,lags=seq(10,300,by=10),formula='rev+lev') {
  
  formula=paste('sdflag~',formula)
  
  rsq<-NULL
  for (i in 1:length(lags)) {
    if (lags[i] > 0){
      p$sdflag<-dplyr::lag(p$sdf,lags[i])
    }
    else{
      p$sdflag<-dplyr::lead(p$sdf,lags[i]*-1)
    }
    
    rsq[i]<- summary(lm(formula=formula,data=p))$r.squared
  }
  #return(rsq)
  # return(lags[rsq==max(rsq)])
  bestlag=lags[rsq==max(rsq)]
  p$dynamiclead<- bestlag
  if (bestlag > 0){
    p$sdflag<-dplyr::lag(p$sdf,bestlag)
  }
  else{
    p$sdflag<-dplyr::lead(p$sdf,bestlag*-1)
  }
  return(p)
  
}
  
findSaccades<-function(ev,threshold=40){
    mindur<-50
    i<-which(abs(ev)>threshold) #find all the times when speed > threshold
    sacoff<-which(diff(i)>mindur) #minimum duration of an accepted saccade
    sacon<-c(1,sacoff+1) #first saccade
    sacoff<-c(sacoff,length(i)) #end of last saccade
    saccade.onset<-i[sacon] #get actual times
    saccade.offset<-i[sacoff] 
    return(data.frame(saccade.onset,saccade.offset))
  }

markSaccades<-function(ev,buffer=15,threshold=40){
  #this function finds and marks saccades given a velocity input
  stimes<-findSaccades(ev,threshold)
  
  #remove saccades without enough data at the end of the file, based on buffer size
  toolong<- stimes$saccade.offset> length(ev)-buffer
  tooshort<- stimes$saccade.onset<buffer+1
  stimes<- filter(stimes, !tooshort, !toolong)
  
  nsaccades=nrow(stimes)
  
  stimes$saccade.onset=stimes$saccade.onset-buffer
  stimes$saccade.offset=stimes$saccade.offset+buffer
  
  s<-1:length(ev)*0
  
  for (k in 1:nsaccades){
    s[stimes$saccade.onset[k]:stimes$saccade.offset[k]]<- k
    if(k>1){
      s[stimes$saccade.offset[k-1]:stimes$saccade.onset[k]]<-(k*-1)
    }
  }
  s[1:stimes$saccade.onset[1]]<- -1
  s[stimes$saccade.offset[nrow(stimes)]:length(s)]<- (nrow(stimes)*-1)-1
  return(s)
}

parabolicdiff <- function(pos,n=7){
  q <- sum(2*((1:n)^2))
  convoutput<- convolve(pos,c(-n:-1, 1:n),type="open")
  convoutput<- convoutput[(n*2):(length(pos)-((n*2)+1))]
  vels<- c(array(convoutput[1],dim=n*2),convoutput,array(convoutput[length(convoutput)],dim=n*2))
  vels <- vels/q*1000
}

maxabs<- function(x){
  m1<-max(x,na.rm=T)
  m2<-min(x,na.rm=T)
  if (abs(m1)>abs(m2)) {
    return(m1)
  } else{
    return(m2)
  }
}

loadnewcsv<- function(r=NULL,path="C:/Users/setup/Desktop/NRTP Vergence/"){
  #This function loads .csv files in a particular folder. They must have the same columns for rbind
  #Saves time by only reading the csv when necessary
  
  #get names of all files in path
  files <- list.files(path=path,pattern='*.csv')
  #extract neuron name eg. Bee-01
  names<-sapply(files, str_match,"^[a-zA-Z]+-[0-9]+",USE.NAMES=FALSE)
  # check for new cells
  if (!is.null(r)){
    files<-files[!names %in% r$neuron] #comparison
  }
  
  nfiles<-length(files)
  
  if (nfiles>0){
    message(c('New Files: ',files))
    loadedfiles <- lapply(paste(path,files,sep=''),read.csv)
    t<-data.frame()
    # t.old<-NULL
    for (i in 1:nfiles) {
      f<- files[i]
      message(paste('Loading:',f))
      temp=loadedfiles[[i]]
      names<-str_match(f,"(^[a-zA-Z]+)-([0-9]+)")
      temp$neuron<-names[1]
      temp$monkey<-names[2]
      temp$cellnum<-as.numeric(names[3])
      temp$sdf<-spikedensity(temp$rasters,sd=10)
      # leadtime<-dynamiclead(temp)
      message(paste('ms of data:',nrow(temp)))
      mutate(temp,
             # sdflag=lag(sdf,leadtime),
             conj.velocity=sqrt((rev^2+lev^2)/2)+sqrt((revV^2+levV^2)/2),
             # s=markSaccades(conj.velocity,buffer=10,threshold=10),
             # slong=markSaccades(conj.velocity,buffer=longbuffer,threshold=10),
             time=row_number(),
             verg.angle=lep-rep,
             verg.velocity=parabolicdiff(verg.angle,7))->
        temp
      
      t <-rbind(t,temp)
    }
    t<- dplyr::select(t, -thp,-tvp,-time)
  }else{
    message('********NO NEW CELLS********')
    t=NULL
  }
  return(t)
}

bootci <- function(t,n=100,alpha=0.05,formula='lagsdf~rev+lev'){
  t %>%
    bootstrap(n) %>%
    do(tidy(lm(formula,.)))%>%
    group_by(term) %>%
    summarize(
      low=quantile(estimate, alpha / 2),
      high=quantile(estimate, 1 - alpha / 2)) ->
    ci
  return(ci)
}

bootciEXPERIMENTAL <- function(t,n=100,alpha=0.05,formula='lagsdf~rev+lev'){
  neuron=t$neuron[1]
  message(paste('Currently working on',neuron))
  t %>%
    bootstrap(n) %>%
    do(tidy(lm(formula,.)))%>%
    group_by(term) %>%
    summarize(
      low=quantile(estimate, alpha / 2),
      high=quantile(estimate, 1 - alpha / 2),
      m=first(estimate)) ->
    ci
  ci$neuron<- neuron
  return(ci)
}

bootciNOCONJ <- function(t,n=100,alpha=0.05,formula='lagsdf~rev+lev'){
  neuron=t$neuron[1]
  message(paste('Currently working on',neuron))
  t %>%
    ungroup() %>%
    filter(saccade.type != 'conj') %>%
    bootstrap(n) %>%
    do(tidy(lm(formula,.)))%>%
    group_by(term) %>%
    summarize(
      low=quantile(estimate, alpha / 2),
      high=quantile(estimate, 1 - alpha / 2),
      m=first(estimate)) ->
    ci
  ci$neuron<- neuron
  return(ci)
}

joinsaccadesuniform<-function(t,buffer=20,threshold=30,saccade.length=150){
  
  findSaccades<-function(ev,threshold=40){
    mindur<-50
    i<-which(abs(ev)>threshold) #find all the times when speed > threshold
    sacoff<-which(diff(i)>mindur) #minimum duration of an accepted saccade
    sacon<-c(1,sacoff+1) #first saccade
    sacoff<-c(sacoff,length(i)) #end of last saccade
    saccade.onset<-i[sacon] #get actual times
    saccade.offset<-i[sacoff] 
    
    return(data.frame(saccade.onset,saccade.offset))
  }
  
  jsac<- function(stimes){
    summary(stimes)
    #input should be an array of length 2: c(onsettime,offsettime, saccade.number,saccade.dur)
    df<- data.frame(time=stimes[[1]]:stimes[[2]])
    df$sacnum<- stimes[[4]]
    df$saccade.dur<- stimes[[3]]
    return(df)
    # return(stimes[[1]]:stimes[[2]])
  }
  
  stimes<-findSaccades(t$conj.velocity,threshold)
  stimes %>%
    mutate(dur=saccade.offset-saccade.onset,
           s=row_number(),
           saccade.onset=saccade.onset-buffer,
           ###########HERE IS WHERE i MAKE SACCADES UNIFORM #######
           saccade.offset=saccade.onset+saccade.length+2*buffer)->
    stimes
  
  x<- do.call('rbind',apply(stimes,1,jsac))
  x %>%
    group_by(sacnum) %>%
    mutate(counter=time-first(time)) ->
    x
  left_join(t,x,by='time')
}

joinsaccades<-function(t,buffer=20,threshold=30){
  findSaccades<-function(ev,threshold=40){
    mindur<-50
    i<-which(abs(ev)>threshold) #find all the times when speed > threshold
    sacoff<-which(diff(i)>mindur) #minimum duration of an accepted saccade
    sacon<-c(1,sacoff+1) #first saccade
    sacoff<-c(sacoff,length(i)) #end of last saccade
    saccade.onset<-i[sacon] #get actual times
    saccade.offset<-i[sacoff] 
    
    return(data.frame(saccade.onset,saccade.offset))
  }
  
  jsac<- function(stimes){
    #input should be an array of length 2: c(onsettime,offsettime)
    df<- data.frame(time=stimes[[1]]:stimes[[2]])
    df$sacnum<- stimes[[3]]
    return(df)
    # return(stimes[[1]]:stimes[[2]])
  }
  
  stimes<-findSaccades(t$conj.velocity,threshold)
  stimes %>%
    mutate(s=row_number(),
           saccade.onset=saccade.onset-buffer,
           saccade.offset=saccade.offset+buffer)->
    stimes
  
  x<- do.call('rbind',apply(stimes,1,jsac))
  x %>%
    group_by(sacnum) %>%
    mutate(counter=time-first(time)) ->
    x
  left_join(t,x,by='time')
}

markEnhancement<- function(v, threshold1=15,threshold2=8){
  require(dplyr)
  
  mindur<-50
  i<-which(abs(v)>threshold2) #find all the times when speed is above the lower threshold
  sacoff<-which(diff(i)>mindur) #minimum duration of an accepted saccade
  sacon<-c(1,sacoff+1) #first saccade
  sacoff<-c(sacoff,length(i)) #end of last saccade
  event.onset<-i[sacon] #get actual times
  event.offset<-i[sacoff] 
  
  stimes<- data.frame(event.onset,event.offset)
  nsaccades=nrow(stimes)

  jsac<- function(stimes){
    summary(stimes)
    #input should be an array of length 2: c(onsettime,offsettime, saccade.number,saccade.dur)
    df<- data.frame(time=stimes[[1]]:stimes[[2]])
    df$enhancenum<- stimes[[4]]
    df$enhance.dur<- stimes[[3]]
    return(df)
    # return(stimes[[1]]:stimes[[2]])
  }
  
  stimes %>%
    mutate(dur=event.offset-event.onset,
           s=row_number())->
    stimes
  
  x<- do.call('rbind',apply(stimes,1,jsac))
  
  
    v<- data.frame(v=v)
    v<- mutate(v, time=row_number())
  
  xx<- left_join(v,x,by='time')
  
  xx %>%
    group_by(enhancenum) %>%
    summarize(max.vel=max(abs(v))) %>%
    filter(max.vel>threshold1)->
    xm
  
  xx %>%
    filter(enhancenum %in% unique(xm$enhancenum)) %>%
    dplyr::select(time,v,enhancenum) ->
    g
  
  
}

```

<!-- ```{r LoadDataset} -->
<!-- #I have loaded all the .csv files using the "loadnewcsv" function -->
<!-- #to save time I load them from the r binary file -->

<!-- t<- readRDS('SOA-NRTP.RDS') -->

<!-- t<- dplyr::filter(t, monkey %in% c('Bee','Ozette'),cellnum>100) -->

<!-- #velocity cells -->
<!-- # t<- dplyr::filter(t,neuron %in% -->
<!-- #   c('Bee-103','Bee-104','Bee-107','Bee-108','Bee-110','Bee-112','Bee-113','Bee-202', -->
<!-- #     'Bee-203','Bee-204','Bee-205','Bee-208','Bee-209','211','Bee-215','Ozette-102', -->
<!-- #     'Ozette-114','Ozette-116','Ozette-117','Ozette-118','Ozette-120','Ozette-121','Ozette-122')) -->

<!-- #testing purposes: -->
<!-- # t<- filter(t,neuron %in% c('Bee-101','Ozette-101')) -->


<!-- t<- group_by(t,neuron) %>% mutate(time=row_number()) -->
<!-- ``` -->

```{r markEnhancements}
t<- mutate(t,verg.velocity=lev-rev)
t %>%
  group_by(neuron) %>%
  mutate(time=row_number()) %>%
  do(markEnhancement(v=.$verg.velocity,threshold2=12,threshold1=50))->
  zz

  zz<- dplyr::select(zz,time,enhancenum)

  t<- left_join(t,zz,by=c('neuron','time'))
  t<-ungroup(t)

  #determine whether it's convergence or divergence
  t %>%
    mutate(verg.enhance=!is.na(enhancenum),
           enhance.type='none',
           verg.direction=verg.velocity>0)->
    t
  i<- t$verg.enhance & !t$verg.direction
  t$enhance.type[i]<- 'divergence'
  i<- t$verg.enhance & t$verg.direction
  t$enhance.type[i]<- 'convergence'
  t$enhance.type<- as.factor(t$enhance.type)
  t$verg.direction<- NULL

  t %>% group_by(neuron) %>%
    do(dynamiclead(p=.,formula='verg.angle+verg.velocity:enhance.type',seq(5,200,by=5))) ->
    t

saveRDS(t,'enhancemarked2.RDS')
```


```{r model}
# t<- readRDS('enhancemarked.RDS')
# t<- readRDS('enhancemarked-NRTP.RDS')
t<- readRDS('enhancemarked2.RDS')

  # t %>% group_by(neuron) %>%
  #   do(dynamiclead(p=.,formula='verg.angle',seq(5,60,by=5))) ->
  #   t

t %>%
  group_by(neuron) %>%
  mutate(sdf20= lag(sdf,20)) ->
  t

t %>% group_by(neuron) %>%
  do(joinsaccades(.,buffer=20,threshold=20))->
  t

t %>%
  group_by(neuron) %>%
  # mutate(bin.velocity=cut(verg.velocity,c(seq(-200,200,by=20)))) %>%
  # filter(!is.na(sacnum)) %>%
  group_by(neuron, sacnum) %>%
  mutate(conj.h=(lep+rep)/2,
         conj.v=(lepV+repV)/2,
         conj.h.amp=last(conj.h)-first(conj.h),
         conj.v.amp=last(conj.v)-first(conj.v),
         conj.angle=atan2(conj.v,conj.h)*180/pi,
         peak.verg.velocity=maxabs(verg.velocity),
         r.amp=sqrt(conj.h^2+conj.v^2),
         verg.amp=last(verg.angle)-first(verg.angle),
         saccade.type='conj',
         saccade.type=replace(saccade.type,verg.amp< -2 & r.amp>2,'diverging'),
         saccade.type=replace(saccade.type,verg.amp> 2& r.amp>2,'converging'),
         saccade.type=replace(saccade.type,is.na(sacnum) | r.amp<2,'no.saccade')) ->
  t

t %>% group_by(neuron) %>%
  filter(saccade.type != 'conj') %>%
  # do(dynamiclead(p=.,formula='verg.angle+verg.velocity',seq(5,200,by=5))) %>%
  # do(tidy(lm('sdflag~verg.angle+verg.velocity:enhance.type',data=.))) %>%
  #below: test of using standard delay  
  do(tidy(lm('sdf20~verg.angle+verg.velocity:enhance.type',data=.))) %>%
  mutate(term=replace(term,term=='verg.velocity:enhance.typenone','Slow.Vergence'),
         term=replace(term,term=='verg.velocity:enhance.typeconvergence','Convergence'),
         term=replace(term,term=='verg.velocity:enhance.typedivergence','Divergence'))->
  ttest

ttest %>%
  dplyr::select(term,estimate) %>%
  group_by(term) %>%
  summarize(e=mean(estimate),std=sd(estimate))->
  m
  
kable(m)
t %>%
  group_by(neuron) %>%
  summarize(dynamiclead=first(dynamiclead)) ->
  s
ttest<- left_join(ttest,s,by='neuron')
ttest %>%
  dplyr::select(-statistic,-std.error,-p.value) %>%
  spread(term,estimate) ->
  tp
           

kable(tp,digits=c(0,2,2,2,2,2))

# saveRDS(tp,'modelparams-noconj-SOA.RDS')

```

```{r bootstrapmodel,fig.height=8,fig.width=12}

##The code below does the boostrap by converting the data.frame to a list of neurons
##This is because bootstrap doesn't work with grouped data
##Then we use lapply to apply the bootciEXPERIMENTAL function and save the result
##Use the command to load 'Boostrap1999results.RDS' to get the saved results of this

# t<- readRDS('enhancemarked.RDS')
# n=unique(t$neuron)
# ci<-readRDS('TempBootstrap1999.RDS') #load the already analyzed cells
# tempci<- do.call('rbind',ci)
# n<- n[!n %in% unique(tempci$neuron)] #limit new analysis to unanalyzed cells
# tlist<-NULL
# for (i in 1:length(n)){
#   tlist[[i]]<- filter(t,neuron==n[i])
# }
# t<-NULL
REDOANALYSIS<- FALSE
if (REDOANALYSIS){
  t<- readRDS('enhanceandsaccadesmarkedSOA.RDS')
  n=unique(t$neuron)
  ci<- readRDS('boot1999noconj-1.RDS')
  nnew<- n[!n %in% unique(ci$neuron)]
  
  #THE BELOW LOOP TAKES HOURS AND HOURS 
  for (i in 1:length(nnew)){
    tt<- filter(t,neuron==nnew[i])
    b<- bootciNOCONJ(tt,n=1999,alpha=0.05,formula='sdflag~verg.angle+verg.velocity:enhance.type')
    saveRDS(b,paste('boottemp',i,sep='_'))
  }
  
  #Read the individual files. 
  #There were 30 when I did it last time, but check how many before running
  temp<-list()
  for (i in 1:30){
    temp[[i]]<- readRDS(paste('boottemp',i,sep='_'))
  }
  
  ci<- readRDS('boot1999noconj-1.RDS')
  cit<- do.call('rbind',temp)  
  
  ci<- rbind(ci,cit)
  
  saveRDS(ci,'Bootstrap1999SOAnoconj.RDS')
} #End block of REDOANSLYSIS -- this takes hours to do

--------------

# ci<- readRDS('Bootstrap1999results.RDS')
ci<- readRDS('Bootstrap1999SOAnoconj.RDS')




ci %>%
  mutate(term=replace(term,term=='verg.velocity:enhance.typenone','Slow.Velocity'),
         term=replace(term,term=='verg.velocity:enhance.typeconvergence','Convergence'),
         term=replace(term,term=='verg.velocity:enhance.typedivergence','Divergence')) %>%
  # group_by(neuron) %>%
  filter(term != '(Intercept)') ->
  pci

#zoom in and show zero crossings
g<-ggplot(pci,aes(factor(term),m))

g+geom_errorbar(aes(ymin=low,ymax=high,color=neuron),size=2,alpha=1/2,width=0.2)+
  geom_hline(yintercept = 0)+
  ylab('Bootstrap conficence interval for parameter estimate')+
  xlab('Term')+
  geom_text(aes(label=neuron))+
  coord_flip()
  # ylim(c(-0.05,0.05))
  # coord_cartesian(ylim=c(-1,1))+
  # coord_flip(ylim=c(-0.05,0.05))

#show only zero crossings
g<-ggplot(filter(pci,low*high<0),aes(factor(term),m))
g+geom_errorbar(aes(ymin=low,ymax=high,color=neuron),size=2,alpha=1/2,width=0.2)+
  geom_hline(yintercept = 0)+
  ylab('Bootstrap conficence interval for parameter estimate')+
  xlab('Term')+
  coord_flip()+
  coord_flip(ylim=c(-0.05,0.05))+
  geom_text(aes(label=neuron),check_overlap=F)
# coord_cartesian(ylim=c(-1,1))+


ci %>%
   mutate(term=replace(term,term=='verg.velocity:enhance.typenone','Slow.Velocity'),
         term=replace(term,term=='verg.velocity:enhance.typeconvergence','Convergence'),
         term=replace(term,term=='verg.velocity:enhance.typedivergence','Divergence')) %>%
  # group_by(neuron) %>%
  mutate(m=(low+high)/2) %>%
  filter(term != '(Intercept)', term != 'verg.angle') ->
  pci

g<-ggplot(pci,aes(factor(term),m))

g+geom_errorbar(aes(ymin=low,ymax=high,color=neuron),size=2,alpha=1/2,width=0.2)+
  geom_hline(yintercept = 0)+
  coord_flip()+
  ylab('Bootstrap conficence interval for parameter estimate')+
  xlab('Term')

# #Determine whether Slow.Vergence and Convergence intervals overlap
# pci %>%
#   group_by(neuron) %>%
#   summarize(lowC=low[term=='Convergence'],
#             highC=high[term=='Convergence'],
#             lowD=low[term=='Divergence'],
#             highD=high[term=='Divergence'],
#             overlap=(lowC < highS & lowC > lowS) | (highC < highS & highC > lowS))->
#   ovCS
# 
# filter(ovCS,overlap==TRUE)
# 
# pci %>%
#   group_by(neuron) %>%
#   summarize(lowC=low[term=='Convergence'],
#             highC=high[term=='Convergence'],
#             lowS=low[term=='Slow.Velocity'],
#             highS=high[term=='Slow.Velocity'],
#             overlap=(lowC < highS & lowC > lowS) | (highC < highS & highC > lowS))->
#   ovCS
# 
# filter(ovCS,overlap==TRUE)

pci %>%
  group_by(neuron) %>%
  summarize(lowC=low[term=='Convergence'],
            highC=high[term=='Convergence'],
            midC=m[term=='Convergence'],
            lowS=low[term=='Slow.Velocity'],
            highS=high[term=='Slow.Velocity'],
            midS=m[term=='Slow.Velocity'],
            lowD=low[term=='Divergence'],
            highD=high[term=='Divergence'],
            midD=m[term=='Divergence'],
            lowA=low[term=='verg.angle'],
            highA=high[term=='verg.angle'],
            overlapZC=lowC*highC<0,
            overlapZD=lowD*highD<0,
            overlapZS=lowS*highS<0,
            overlapZA=lowA*highA<0,
            overlapCS=(lowC < highS & lowC > lowS) | (highC < highS & highC > lowS) | (midS< highC & midS > lowC),
            overlapCD=(lowC < highD & lowC > lowD) | (highC < highD & highC > lowD) | (midD< highC & midD > lowC),
            overlapDS=(lowD < highS & lowD > lowS) | (highD < highS & highD > lowS) | (midS< highD & midS > lowD),
            overlapAny=(overlapZC | overlapZD | overlapZS | overlapCS | overlapCD| overlapDS))->
  ov

ov %>%
  filter(overlapAny) %>%
  select(c(1,11,12,13,14,15,16)) %>%
  kable()

write.csv(ov,'BoostrapOverlapAnalysis.CSV')

zz<- left_join(pci,select(ov,neuron,overlapAny),by='neuron')

mutate()

ggplot(filter(zz,overlapAny,term != 'verg.angle'),aes(factor(term),m))+
 geom_errorbar(aes(ymin=low,ymax=high,color=neuron),size=1,alpha=1/2,width=0.2)+
  geom_hline(yintercept = 0)+
  ylab('Bootstrap conficence interval for parameter estimate')+
  xlab('Term')+
  # coord_flip()+
  theme(legend.position='top')+
  # coord_flip(ylim=c(-0.05,0.05))+
  # geom_text(aes(label=neuron),check_overlap=F)+
  facet_wrap(~neuron,ncol=3,scales='free_y')

ggsave('BootstrapOverlaps.PNG',height=6,width=9)

ggplot(zz,aes(factor(term),m))+
 geom_errorbar(aes(ymin=low,ymax=high,color=overlapAny),size=1,alpha=1/2,width=0.2)+
  geom_hline(yintercept = 0)+
  ylab('Bootstrap conficence interval for parameter estimate')+
  xlab('Term')+
  # coord_flip()+
  theme(legend.position='top')+
  # coord_flip(ylim=c(-0.05,0.05))+
  # geom_text(aes(label=neuron),check_overlap=F)+
  facet_wrap(~neuron,ncol=3,scales='free_y')

ggsave('BootstrapAll.PNG',height=20,width=6)
```

```{r lags,fig.height=8,fig.width=12}
t %>%
  group_by(neuron) %>%
  summarize(lag=first(dynamiclead)) ->
  s

qplot(lag,data=s)
ggplot(s)+geom_bar(aes(as.factor(neuron),lag),stat='identity')
# qplot(neuron,lag,data=s,geom='line')

ggplot(s)+geom_boxplot(aes(x=1,lag))
```
